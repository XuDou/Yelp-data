{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ijson\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We choose data from Las Vegas as an illustrative example.\n",
    "\n",
    "data = pd.read_csv('LasVegas_tips_after2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>KPgyqG3MyFUDK7GRbUg51A</td>\n",
       "      <td>Kelly Paun was so full of knowledge and was so...</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Landmarks &amp; Historical Buildings, Travel Servi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Pink Jeep Tours</td>\n",
       "      <td>4.5</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>JtNVcqioJhS8GZ-If30oHg</td>\n",
       "      <td>Make sure you sign up for Emerald club before ...</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automotive, Hotels &amp; Travel, Car Rental</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>National Car Rental</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>gh6__q2WXFuyN8gt6VAnWw</td>\n",
       "      <td>Very delicious food with very fast delivery!</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'Ambience': \"{'romanti...</td>\n",
       "      <td>Seafood, Restaurants, Steakhouses, Greek, Fren...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Vila Algarve</td>\n",
       "      <td>4.5</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>gh6__q2WXFuyN8gt6VAnWw</td>\n",
       "      <td>Amazing Portuguese food! Linguica (chirizo) is...</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'Ambience': \"{'romanti...</td>\n",
       "      <td>Seafood, Restaurants, Steakhouses, Greek, Fren...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Vila Algarve</td>\n",
       "      <td>4.5</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>gh6__q2WXFuyN8gt6VAnWw</td>\n",
       "      <td>All the way from Porto portugal lost off love!...</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'Ambience': \"{'romanti...</td>\n",
       "      <td>Seafood, Restaurants, Steakhouses, Greek, Fren...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Vila Algarve</td>\n",
       "      <td>4.5</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id  \\\n",
       "0           8  KPgyqG3MyFUDK7GRbUg51A   \n",
       "1          20  JtNVcqioJhS8GZ-If30oHg   \n",
       "2          34  gh6__q2WXFuyN8gt6VAnWw   \n",
       "3          55  gh6__q2WXFuyN8gt6VAnWw   \n",
       "4          56  gh6__q2WXFuyN8gt6VAnWw   \n",
       "\n",
       "                                                text        date  \\\n",
       "0  Kelly Paun was so full of knowledge and was so...  2017-03-23   \n",
       "1  Make sure you sign up for Emerald club before ...  2018-03-29   \n",
       "2       Very delicious food with very fast delivery!  2017-09-24   \n",
       "3  Amazing Portuguese food! Linguica (chirizo) is...  2017-12-11   \n",
       "4  All the way from Porto portugal lost off love!...  2018-04-10   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  {'Alcohol': 'full_bar', 'Ambience': \"{'romanti...   \n",
       "3  {'Alcohol': 'full_bar', 'Ambience': \"{'romanti...   \n",
       "4  {'Alcohol': 'full_bar', 'Ambience': \"{'romanti...   \n",
       "\n",
       "                                          categories       city  \\\n",
       "0  Landmarks & Historical Buildings, Travel Servi...  Las Vegas   \n",
       "1            Automotive, Hotels & Travel, Car Rental  Las Vegas   \n",
       "2  Seafood, Restaurants, Steakhouses, Greek, Fren...  Las Vegas   \n",
       "3  Seafood, Restaurants, Steakhouses, Greek, Fren...  Las Vegas   \n",
       "4  Seafood, Restaurants, Steakhouses, Greek, Fren...  Las Vegas   \n",
       "\n",
       "                  name  stars  review_count  \n",
       "0      Pink Jeep Tours    4.5           136  \n",
       "1  National Car Rental    4.0           224  \n",
       "2         Vila Algarve    4.5           189  \n",
       "3         Vila Algarve    4.5           189  \n",
       "4         Vila Algarve    4.5           189  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "business_id      object\n",
       "text             object\n",
       "date             object\n",
       "attributes       object\n",
       "categories       object\n",
       "city             object\n",
       "name             object\n",
       "stars           float64\n",
       "review_count      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=65280, step=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = np.array(data['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.0 means good; 0.0 means not good, bad ...\n",
    "stars[stars<4.0] = 0.0\n",
    "stars[stars>=4.0] = 1.0\n",
    "data['class'] = stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A glimpse onto the statistics of the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    65280.000000\n",
       "mean         3.908058\n",
       "std          0.703868\n",
       "min          1.000000\n",
       "25%          3.500000\n",
       "50%          4.000000\n",
       "75%          4.500000\n",
       "max          5.000000\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    65280.000000\n",
       "mean         0.672733\n",
       "std          0.469219\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the tips column with the stars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column which combines \"text\" and \"stars\"\n",
    "\n",
    "# Turn stars into strings, add a space in front of each item\n",
    "\n",
    "data['stars'] = data['stars'].map(str).apply(lambda x: ' ' + x);\n",
    "\n",
    "data['tips_stars'] = data[\"text\"] + data['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Park valet. It'll be the best $20 you spend because it gives you free valet parking nearly everywhere else (like Bellagio). Any MGM resort on the Strip is included, and there's many.  3.0\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[98]['tips_stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training set and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "...     data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer =  TfidfVectorizer(max_features=1200,stop_words='english',ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1200, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(data['tips_stars'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = vectorizer.transform(train_set['tips_stars'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = vectorizer.transform(test_set['tips_stars'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43737, 1200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21543, 1200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "## The output of K_Means is an array of labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=16, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 16\n",
    "KMeans_model = KMeans(n_clusters=K, init='k-means++', max_iter=100, n_init=1)\n",
    "KMeans_model.fit(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  5,  5, ...,  5, 12,  5], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_model.predict(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " mango\n",
      " rice\n",
      " tea\n",
      " try\n",
      " green tea\n",
      " green\n",
      " good\n",
      " boba\n",
      " milk\n",
      " ice\n",
      "Cluster 1:\n",
      " food amazing\n",
      " amazing\n",
      " food\n",
      " food amazing service\n",
      " amazing service\n",
      " service\n",
      " great\n",
      " amazing food\n",
      " place\n",
      " great food\n",
      "Cluster 2:\n",
      " good\n",
      " food\n",
      " good food\n",
      " service\n",
      " food good\n",
      " good service\n",
      " really good\n",
      " really\n",
      " service good\n",
      " great\n",
      "Cluster 3:\n",
      " best place\n",
      " best\n",
      " place\n",
      " vegas\n",
      " place vegas\n",
      " place town\n",
      " town\n",
      " eat\n",
      " place eat\n",
      " great\n",
      "Cluster 4:\n",
      " place\n",
      " great place\n",
      " great\n",
      " awesome\n",
      " nice\n",
      " favorite\n",
      " good\n",
      " nice place\n",
      " awesome place\n",
      " place great\n",
      "Cluster 5:\n",
      " service\n",
      " awesome\n",
      " don\n",
      " food\n",
      " great\n",
      " time\n",
      " just\n",
      " nice\n",
      " friendly\n",
      " excellent\n",
      "Cluster 6:\n",
      " guys\n",
      " great\n",
      " thanks\n",
      " awesome\n",
      " love\n",
      " job\n",
      " best\n",
      " service\n",
      " work\n",
      " fast\n",
      "Cluster 7:\n",
      " great\n",
      " service\n",
      " food\n",
      " great service\n",
      " great food\n",
      " food great\n",
      " service great\n",
      " food great service\n",
      " customer\n",
      " customer service\n",
      "Cluster 8:\n",
      " fun\n",
      " fun place\n",
      " place\n",
      " great\n",
      " good\n",
      " atmosphere\n",
      " super\n",
      " time\n",
      " kids\n",
      " friendly\n",
      "Cluster 9:\n",
      " love\n",
      " love place\n",
      " place\n",
      " love love\n",
      " food\n",
      " great\n",
      " love food\n",
      " service\n",
      " love love love\n",
      " love place great\n",
      "Cluster 10:\n",
      " dinner\n",
      " lunch\n",
      " great\n",
      " food\n",
      " night\n",
      " ayce\n",
      " menu\n",
      " good\n",
      " 95\n",
      " family\n",
      "Cluster 11:\n",
      " best\n",
      " vegas\n",
      " town\n",
      " ve\n",
      " las vegas\n",
      " las\n",
      " food\n",
      " hands\n",
      " pizza\n",
      " best pizza\n",
      "Cluster 12:\n",
      " amazing\n",
      " amazing food\n",
      " service\n",
      " food\n",
      " place amazing\n",
      " great\n",
      " place\n",
      " amazing service\n",
      " service amazing\n",
      " staff\n",
      "Cluster 13:\n",
      " delicious\n",
      " food\n",
      " delicious food\n",
      " food delicious\n",
      " service\n",
      " great\n",
      " fresh\n",
      " friendly\n",
      " place\n",
      " good\n",
      "Cluster 14:\n",
      " check\n",
      " free\n",
      " yelp\n",
      " yelp check\n",
      " check yelp\n",
      " smog\n",
      " offer\n",
      " don\n",
      " sure\n",
      " 10\n",
      "Cluster 15:\n",
      " vegan\n",
      " options\n",
      " vegan options\n",
      " menu\n",
      " vegetarian\n",
      " great\n",
      " food\n",
      " friendly\n",
      " delicious\n",
      " amazing\n"
     ]
    }
   ],
   "source": [
    "order_centroids = KMeans_model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(K):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reducing: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_components = 50\n",
    "\n",
    "#truncatedSVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.54680638e-01,  2.21572572e-01,  3.85007115e-01, ...,\n",
       "        -4.67318771e-02, -3.91596332e-02,  8.24949614e-04],\n",
       "       [ 3.89008861e-02,  2.52419395e-02,  5.06642724e-03, ...,\n",
       "        -3.51334873e-02,  2.90343731e-02,  3.30482631e-02],\n",
       "       [ 9.43313662e-03,  4.42728750e-03,  3.27046629e-04, ...,\n",
       "         5.87005142e-03,  5.11046812e-03,  7.46401724e-03],\n",
       "       ...,\n",
       "       [ 4.55151613e-02,  9.14722905e-03, -5.32490831e-03, ...,\n",
       "        -2.80178211e-02, -8.93588100e-02,  2.64744936e-02],\n",
       "       [ 1.22982806e-01,  1.73237072e-01, -7.08034122e-02, ...,\n",
       "         3.33315879e-02, -9.56859733e-02,  4.92171534e-02],\n",
       "       [ 5.13251087e-02,  2.03369681e-02, -1.82036793e-03, ...,\n",
       "        -6.20539241e-02,  4.09402599e-02,  7.48513358e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.transform(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.54680443e-01,  2.21569187e-01,  3.85000474e-01, ...,\n",
       "         7.10866682e-02, -3.49273991e-02,  2.48064727e-01],\n",
       "       [ 3.89010309e-02,  2.52359260e-02,  5.07008116e-03, ...,\n",
       "        -3.64508112e-02,  2.03548697e-02,  9.09534719e-03],\n",
       "       [ 9.43341579e-03,  4.42574995e-03,  3.27547440e-04, ...,\n",
       "        -4.72404461e-03,  3.94038855e-04,  3.22621335e-03],\n",
       "       ...,\n",
       "       [ 4.55148521e-02,  9.15253072e-03, -5.32833820e-03, ...,\n",
       "         1.52547807e-02,  3.63006687e-02, -1.21090900e-02],\n",
       "       [ 1.22984157e-01,  1.73233391e-01, -7.08044634e-02, ...,\n",
       "        -1.34381476e-02,  3.99151882e-02, -6.01916098e-02],\n",
       "       [ 5.13241221e-02,  2.03364541e-02, -1.81739993e-03, ...,\n",
       "         6.51001196e-03, -4.56209261e-02,  1.19366507e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit_transform(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<43737x1200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 231554 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_set[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0,solver='lbfgs',multi_class='multinomial').fit(train_tfidf,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227747673594439"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_tfidf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.700505964814557"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_tfidf,test_set[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      43737\n",
       "business_id     43737\n",
       "text            43736\n",
       "date            43737\n",
       "attributes      42609\n",
       "categories      43722\n",
       "city            43737\n",
       "name            43737\n",
       "stars           43737\n",
       "review_count    43737\n",
       "class           43737\n",
       "tips_stars      43736\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      29505\n",
       "business_id     29505\n",
       "text            29504\n",
       "date            29505\n",
       "attributes      28946\n",
       "categories      29501\n",
       "city            29505\n",
       "name            29505\n",
       "stars           29505\n",
       "review_count    29505\n",
       "class           29505\n",
       "tips_stars      29504\n",
       "dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set[\"class\"]==1.0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746004527059469"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29505/43737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xudou/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier(n_estimators=10, max_depth=4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.fit(train_tfidf,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746233166426595"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.score(train_tfidf,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689411873926565"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_clf.score(test_tfidf,test_set[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    "             \"Merley has the best squooshy kitten belly.\",\n",
    "             \"Google Translate app is incredible.\",\n",
    "             \"If you open 100 tab in google you get a smiley face.\",\n",
    "             \"Best cat photo I've ever taken.\",\n",
    "             \"Climbing ninja cat.\",\n",
    "             \"Impressed with google map feedback.\",\n",
    "             \"Key promoter extension for Google Chrome.\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=2, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " google\n",
      " ninja\n",
      " climbing\n",
      " app\n",
      " feedback\n",
      " impressed\n",
      " incredible\n",
      " translate\n",
      " map\n",
      " cat\n",
      "Cluster 1:\n",
      " best\n",
      " ve\n",
      " photo\n",
      " taken\n",
      " belly\n",
      " merley\n",
      " kitten\n",
      " squooshy\n",
      " restaurant\n",
      " came\n"
     ]
    }
   ],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
